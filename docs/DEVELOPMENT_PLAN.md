# ZommaKG Development Plan

## Executive Summary

This document outlines a phased development plan for implementing the ZommaKG Python package - an embedded knowledge graph library with zero infrastructure requirements. The package transforms the existing Neo4j-based system into a pip-installable library using DuckDB, LanceDB, and Parquet for storage.

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KnowledgeGraph API                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Ingestion Pipeline  â”‚  Query Pipeline  â”‚  Shell Interface  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Storage Layer                           â”‚
â”‚         DuckDB (SQL) + LanceDB (Vectors) + Parquet         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Providers (LLM + Embedding)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           Types + Config + Utils (Foundation)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 1: Foundation (Week 1-2)

**Goal**: Establish core infrastructure that all other components depend on.

### 1.1 Type System (`types/`)

**Status**: âœ… COMPLETE

**Files implemented**:
- `types/entities.py` - Entity, EntityType, EnumeratedEntity, EntityMatchDecision, EntityGroup, EntityResolution âœ…
- `types/facts.py` - Fact, ExtractedFact âœ…
- `types/chunks.py` - Chunk, Document, DocumentPayload, ChunkInput âœ…
- `types/topics.py` - Topic, TopicResolution, TopicDefinition, BatchTopicDefinitions âœ…
- `types/results.py` - QueryResult, IngestResult, SearchResult, ExtractionResult, CritiqueResult, ChainOfThoughtResult, EntityDedupeResult, QuestionType, EntityHint, SubQuery, QueryDecomposition, DateExtraction, CanonicalEntity, EntityDeduplicationOutput, MergeRecord âœ…

**Ported from**: `ZommaLabsKG/zomma_kg/schemas/extraction.py`, `query/shared_schemas.py`, `query/schemas.py`

**Deliverable**: 31 Pydantic models with full type hints, validated with mypy. âœ…

---

### 1.2 Configuration System (`config/`)

**Status**: âœ… COMPLETE

**Files implemented**:
- `config/settings.py` - KGConfig class with env + TOML file + programmatic overrides âœ…

**Key features**:
- Environment variables: `ZOMMA_*` prefix âœ…
- TOML config file support: `from_file()` and `to_file()` âœ…
- Programmatic overrides via constructor kwargs âœ…
- Python 3.10 (tomli) and 3.11+ (tomllib) support âœ…

**Deliverable**: KGConfig loading from all three sources with proper precedence. âœ…

---

### 1.3 Provider Abstraction (`providers/`)

**Status**: âœ… COMPLETE

**Files implemented**:
- `providers/base.py` - LLMProvider, EmbeddingProvider ABCs âœ…
- `providers/llm/openai.py` - OpenAILLMProvider (LangChain-based) âœ…
- `providers/embedding/openai.py` - OpenAIEmbeddingProvider (LangChain-based) âœ…

**Features**:
- `generate()`, `generate_structured()`, `stream()` for LLM âœ…
- `embed()`, `embed_single()` for embeddings âœ…
- `with_model()` for easy model switching âœ…
- Lazy imports via `__getattr__` in `__init__.py` âœ…
- Default model: `gpt-5.1` (configurable) âœ…

**Deliverable**: OpenAI provider implementations (minimum viable). âœ…

---

## Phase 2: Storage Layer (Week 2-3)

**Status**: âœ… COMPLETE

**Goal**: Implement embedded storage replacing Neo4j.

### 2.1 Storage Base (`storage/base.py`)

**Create abstract interface**:
```python
class StorageBackend(ABC):
    async def write_entities(self, entities: list[Entity]) -> None: ...
    async def write_chunks(self, chunks: list[Chunk]) -> None: ...
    async def write_facts(self, facts: list[Fact]) -> None: ...
    async def get_entity(self, name: str) -> Entity | None: ...
    async def get_chunks_for_entity(self, name: str) -> list[Chunk]: ...
    # ... etc
```

---

### 2.2 Parquet Backend (`storage/parquet/`)

**Files to implement**:
- `backend.py` - ParquetBackend class
- `tables.py` - Table schemas and PyArrow operations
- `migrations.py` - Schema versioning

**Table schemas**:

| Table | Columns |
|-------|---------|
| `entities.parquet` | uuid, name, summary, entity_type, aliases, created_at, updated_at |
| `chunks.parquet` | uuid, document_uuid, content, header_path, position, document_date |
| `facts.parquet` | uuid, content, subject_uuid, subject_name, object_uuid, object_name, relationship_type, date_context |
| `relationships.parquet` | id, from_uuid, from_type, to_uuid, to_type, rel_type, fact_id, description |
| `topics.parquet` | uuid, name, definition, parent_topic |
| `documents.parquet` | uuid, name, document_date, source_path, file_type, metadata |

**Deliverable**: ParquetBackend with CRUD operations for all tables.

---

### 2.3 LanceDB Integration (`storage/lancedb/`)

**Files to implement**:
- `indices.py` - Vector index management

**Vector indices**:
- `entities.lance` - Entity name + summary embeddings
- `facts.lance` - Fact content embeddings
- `topics.lance` - Topic definition embeddings

**Operations**:
- `index_entities(entities, embeddings)` - Add/update entity vectors
- `search_entities(query_vector, limit, threshold)` - Similarity search
- `search_facts(query_vector, limit, threshold)` - Fact search

**Deliverable**: LanceDB wrapper with filtered vector search.

---

### 2.4 DuckDB Query Layer (`storage/duckdb/`)

**Files to implement**:
- `queries.py` - SQL query implementations

**Query translations from Neo4j Cypher**:

| Query | SQL Equivalent |
|-------|----------------|
| Entity lookup | `SELECT * FROM entities WHERE name = ?` |
| Entity chunks | `JOIN relationships ON from_uuid = entity.uuid JOIN chunks ON ...` |
| 1-hop neighbors | Self-join on relationships via fact_id |
| Fact retrieval | LanceDB search + DuckDB join |

**Deliverable**: All query patterns from QUERYING_SYSTEM.md implemented in SQL.

---

## Phase 3: Ingestion Pipeline (Week 3-5)

**Status**: âœ… COMPLETE

**Goal**: Port 3-phase ingestion system to embedded storage.

### 3.1 Chunking System (`ingestion/chunking/`)

**Files to implement**:
- `pdf.py` - PDF â†’ Markdown (Gemini vision)
- `markdown.py` - Markdown â†’ Chunks (header-aware)
- `text.py` - Plain text chunking

**Port from**: `ZommaLabsKG/zomma_kg/chunker/`

**Algorithm**:
1. PDF â†’ Markdown via Gemini 2.5 Pro vision
2. Parse markdown line-by-line tracking header stack
3. Split on paragraph boundaries (blank lines)
4. Keep HTML tables atomic
5. Filter chunks < 50 characters

**Deliverable**: Complete chunking with PDF, markdown, text support.

---

### 3.2 Extraction System (`ingestion/extraction/`)

**Files to implement**:
- `extractor.py` - Chain-of-thought extraction
- `critique.py` - Quality assessment
- `schemas.py` - Extraction Pydantic schemas

**Port from**: `ZommaLabsKG/zomma_kg/pipeline/extractor.py`

**Two-step extraction**:
1. **Entity Enumeration**: Extract ALL entities (name, type, summary)
2. **Relationship Generation**: Generate facts using ONLY enumerated entities

**Critique/Reflexion**: LLM verifies extraction, optional re-extraction on failure.

**Deliverable**: Extractor with critique loop.

---

### 3.3 Resolution System (`ingestion/resolution/`)

**Status**: âœ… COMPLETE

**Files implemented**:
- `entity_dedup.py` - In-document deduplication âœ… COMPLETE
- `entity_registry.py` - Cross-document matching âœ… COMPLETE
- `topic_resolver.py` - Topic ontology resolution âœ… COMPLETE

**Port from**:
- `ZommaLabsKG/zomma_kg/pipeline/entity_dedup.py`
- `ZommaLabsKG/zomma_kg/pipeline/entity_registry.py`

**Deduplication algorithm** (implemented in `entity_dedup.py`):
1. Generate embeddings (via embedding provider) âœ…
2. Compute similarity matrix using scipy.spatial.distance.cdist âœ…
3. Build edges where similarity >= threshold (default 0.70) âœ…
4. Union-Find to find connected components âœ…
5. Greedy BFS ordering for batch coherence âœ…
6. Overlapping batches for large clusters (>15 entities) âœ…
7. LLM verification with subsidiary awareness âœ…
8. Build UUID remapping and merge history âœ…

**Output types** (added to `types/results.py`):
- `CanonicalEntity` - Deduplicated entity with UUID, aliases, source indices
- `EntityDeduplicationOutput` - Full result with canonical entities and index mapping
- `MergeRecord` - Audit trail of merge decisions

**Tests**: 31 tests in `tests/test_entity_dedup.py` and `tests/test_types.py`

**Deliverable**: Full deduplication pipeline.

**Cross-document resolution** (implemented in `entity_registry.py`):
1. Embed each entity as `{name}: {summary}` âœ…
2. Search LanceDB for top 25 candidates (threshold 0.50) âœ…
3. LLM verification with subsidiary awareness (gpt-5-mini) âœ…
4. Summary merging via LLM on match âœ…
5. Return uuid_remap and summary_updates âœ…
6. Parallel processing with configurable concurrency (default 10) âœ…
7. Error handling with fallback to "new entity" on LLM failure âœ…

**Output types** (added to `types/results.py`):
- `EntityRegistryMatch` - LLM match decision with confidence
- `EntityResolutionResult` - new_entities, uuid_remap, summary_updates

**Tests**: 17 tests in `tests/test_entity_registry.py`

**Topic ontology resolution** (implemented in `topic_resolver.py`):
1. Load curated ontology from JSON (`financial_topics.json`, 232 topics) âœ…
2. Hash-based change detection for lazy reload âœ…
3. Generate embeddings as `{label}: {definition}` + `{synonym}: {definition}` âœ…
4. Vector search against ontology in LanceDB âœ…
5. Batched LLM verification (~10 per call) with bounded concurrency âœ…
6. Dictionary lookup by topic name for robust decision matching âœ…
7. Collect unmatched topics in `new_topics` (toggleable) âœ…

**Output types** (added to `types/topics.py`):
- `TopicResolutionResult` - resolved_topics, uuid_remap, new_topics
- `TopicMatchDecision` - LLM decision for single topic match
- `BatchTopicMatchResponse` - Batched LLM response

**Tests**: 29 tests in `tests/test_topic_resolver.py`

---

### 3.4 Assembly System (`ingestion/assembly/`)

**Status**: âœ… COMPLETE

**Files implemented**:
- `assembler.py` - Write to storage âœ… COMPLETE

**Port from**: `ZommaLabsKG/zomma_kg/pipeline/bulk_writer.py`

**Write order** (implemented):
1. Documents âœ…
2. Chunks (reference document) âœ…
3. Entities with embeddings âœ…
4. Facts with embeddings âœ…
5. Topics with embeddings âœ…
6. Relationships (chunk-centric fact pattern) âœ…

**Features**:
- Parallel embedding generation via `asyncio.gather()` âœ…
- Embedding count validation âœ…
- Error handling with progress logging âœ…
- Unique relationship IDs âœ…

**Output types** (added to `types/results.py`):
- `AssemblyInput` - document, chunks, entities, facts, topics
- `AssemblyResult` - counts of items written

**Tests**: 21 tests in `tests/test_assembler.py`

**Key change**: Write to Parquet + LanceDB instead of Neo4j.

**Deliverable**: Assembler writing to embedded storage. âœ…

---

## Phase 4: Query Pipeline (Week 5-6)

**Status**: âœ… COMPLETE

**Goal**: Port V7 GraphRAG query system.

### 4.1 Query Pipeline (`query/`)

**Files implemented**:
- `pipeline.py` - V7 orchestrator (GraphRAGPipeline) âœ…
- `decomposer.py` - Question decomposition âœ…
- `researcher.py` - Per-subquery research âœ…
- `synthesizer.py` - Answer synthesis âœ…
- `context_builder.py` - Context assembly âœ…
- `types.py` - Pipeline types (PipelineResult, SubAnswer, StructuredContext) âœ…

**Port from**: `ZommaLabsKG/zomma_kg/query/`

**Pipeline phases**:
1. **Decompose**: Break question into sub-queries with entity/topic hints âœ…
2. **Research**: Parallel retrieval for each sub-query (semaphore-bounded) âœ…
3. **Assemble**: Dedupe, filter by relevance, order context âœ…
4. **Synthesize**: Question-type-aware answer generation âœ…

**Features**:
- Parallel sub-query research with configurable concurrency âœ…
- Resolution caching across sub-queries âœ…
- Comprehensive timing metrics âœ…
- Graceful error handling with fallbacks âœ…

**Tests**: `tests/test_query_pipeline.py`

**Key change**: Replace Cypher with DuckDB + LanceDB queries.

**Deliverable**: Complete V7 query pipeline. âœ…

---

## Phase 5: Agent Interface (Week 6-7)

**Status**: âœ… COMPLETE (MCP Server approach)

**Goal**: Provide LLM agents with knowledge graph query capabilities.

### 5.1 MCP Server (`mcp/`)

**Approach changed**: Instead of a virtual filesystem shell, we now expose a single
MCP tool (`kg_execute`) that accepts command strings. This aligns with the skill
definition in `zomma_kg/skills/kg-query/SKILL.md`.

**Files implemented**:
- `mcp/__init__.py` - Module init âœ…
- `mcp/server.py` - MCP server with `kg_execute` tool âœ…
- `mcp/__main__.py` - Entry point for `python -m zomma_kg.mcp` âœ…

**Commands (via kg_execute tool)**:
| Command | Purpose | Status |
|---------|---------|--------|
| `find` | Resolve names â†’ canonical entities/topics | âœ… Done |
| `search` | Find connections between nodes | âœ… Done |
| `cat` | Expand fact details (by result number) | âœ… Done |
| `info` | Entity/topic summary | âœ… Done |
| `ls` | Browse entities, topics, documents | âœ… Done |
| `stats` | Knowledge base statistics | âœ… Done |

**Workflow**: Agents use the documented `find â†’ search â†’ cat` pattern.
Session state maintains search results so `cat 1` references previous search.

**Usage**:
```bash
# Run MCP server
python -m zomma_kg.mcp --kb ./my_kb

# Claude Desktop config
{
    "mcpServers": {
        "zomma-kg": {
            "command": "python",
            "args": ["-m", "zomma_kg.mcp", "--kb", "./my_kb"]
        }
    }
}
```

**Deliverable**: MCP server with kg_execute tool. âœ…

### 5.2 Legacy Shell (Deprecated)

The `api/shell.py` KGShell class is deprecated in favor of the MCP approach.
It may be removed in a future version.

---

## Phase 6: Public API (Week 7-8)

**Status**: âœ… COMPLETE

**Goal**: Implement KnowledgeGraph class and CLI.

### 6.1 KnowledgeGraph Class (`api/`)

**Files implemented**:
- `knowledge_graph.py` - Main class âœ…
- `convenience.py` - Top-level functions âœ…
- `shell.py` - Shell interface (stub, see Phase 5) â³

**API surface**:
```python
kg = KnowledgeGraph("./my_kb")

# Ingestion
await kg.ingest_pdf("doc.pdf")
await kg.ingest_markdown("doc.md")
await kg.ingest_chunks(chunks)

# Query
result = await kg.query("What were the findings?")
entities = await kg.search_entities("apple")

# Shell
shell = kg.shell()
shell.execute("ls /kg/entities/")

# Sync wrappers
kg.ingest_pdf_sync("doc.pdf")
kg.query_sync("What were the findings?")
```

**Note**: `KGShell` is still a placeholder. The above shell calls are not yet implemented.

**Deliverable**: Complete KnowledgeGraph class (shell interface pending).

---

### 6.2 CLI (`cli/`)

**Status**: âœ… COMPLETE

**Files implemented**:
- `__init__.py` - CLI entry point (typer-based) âœ…
- `__main__.py` - Python -m entry point âœ…

**Commands**:
```bash
zomma-kg ingest report.pdf --kb ./my_kb     # âœ… Implemented
zomma-kg query "What were the risks?" --kb ./my_kb  # âœ… Implemented
zomma-kg info --kb ./my_kb                  # âœ… Implemented
zomma-kg shell --kb ./my_kb                 # â³ Placeholder (KGShell not implemented)
zomma-kg export --format json --kb ./my_kb  # âŒ Not implemented
```

**Deliverable**: CLI with core commands. âœ…

---

## Known Issues

### Entity Deduplication Bug (test_kb_refactor)

**Status**: ğŸ› Open

**Observed**: When running the MCP server against `test_kb_refactor`, entities appear multiple times with different UUIDs:
- "Federal Reserve System" appears 3 times
- "Federal Reserve" appears 2 times
- "Beige Book" appears 4 times

**Expected**: Each canonical entity should appear exactly once after deduplication.

**Root Cause**: Investigation needed - likely the `deduplicate_entities` function is not being applied correctly during ingestion, or the test KB was created before deduplication was implemented.

**Impact**: Query results may return duplicate entities, inflating result counts.

**Fix**: Re-ingest test documents with proper deduplication or investigate the dedup pipeline.

---

## Phase 7: Testing & Polish (Week 8-9)

**Status**: â³ PARTIAL

### 7.1 Unit Tests

- `tests/test_types.py` - Pydantic model validation âœ…
- `tests/test_config.py` - Config loading from all sources âŒ
- `tests/test_storage.py` - Parquet/LanceDB operations âŒ
- `tests/test_entity_dedup.py` - Entity deduplication âœ…
- `tests/test_entity_registry.py` - Cross-document entity resolution âœ…
- `tests/test_topic_resolver.py` - Topic ontology resolution âœ…
- `tests/test_assembler.py` - Assembly pipeline âœ…
- `tests/test_query_pipeline.py` - Query pipeline âœ…
- `tests/test_knowledge_graph.py` - Main API âœ…
- `tests/test_mcp_server.py` - MCP server command flow âœ…
- `tests/test_parquet_append_scalability.py` - Parquet append scalability âœ…
- `tests/test_shell.py` - Shell commands âŒ (depends on Phase 5)

### 7.2 Integration Tests

- End-to-end: PDF â†’ ingest â†’ query â†’ answer âŒ
- Multi-document knowledge base âŒ
- Shell navigation scenarios âŒ (depends on Phase 5)

### 7.3 Documentation

- README.md quickstart âœ…
- Developer guide (`docs/DEVELOPER_GUIDE.md`) âœ…
- API reference (docstrings) â³ Partial
- Migration guide from Neo4j âŒ

---

## Dependency Graph

```
Phase 1: Foundation
    types/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    config/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    providers/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                        â”‚
                                        v
Phase 2: Storage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    storage/parquet/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    storage/lancedb/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    storage/duckdb/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                        â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            v
Phase 3: Ingestion              Phase 4: Query
    chunking/ â”€â”€â”€â”€â”€â”€â”               decomposer.py
    extraction/ â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   researcher.py
    resolution/ â”€â”€â”€â”€â”¤               synthesizer.py
    assembly/ â”€â”€â”€â”€â”€â”€â”˜                   â”‚
            â”‚                           â”‚
            v                           v
Phase 5: Shell â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Phase 6: API
    commands.py                     knowledge_graph.py
    path_resolver.py                cli/
```

---

## What to Port vs Rewrite

### Port (adapt for new storage):

| Component | Port From | Adaptation Needed |
|-----------|-----------|-------------------|
| Extraction prompts | `pipeline/extractor.py` | Change LLM client |
| Dedup algorithm | `pipeline/entity_dedup.py` | Use LanceDB for similarity |
| Query decomposition | `query/decomposer.py` | Minimal changes |
| Context builder | `query/context_builder.py` | Minimal changes |

### Rewrite:

| Component | Why |
|-----------|-----|
| Storage layer | Neo4j â†’ Parquet/LanceDB/DuckDB |
| Graph queries | Cypher â†’ SQL |
| Bulk writer | Neo4j batching â†’ Parquet append |
| Shell interface | New feature |

---

## Milestone Checkpoints

| Milestone | Week | Deliverable | Status |
|-----------|------|-------------|--------|
| **M1** | 2 | Types + Config + Storage reads/writes working | âœ… Complete |
| **M2** | 4 | Can ingest a PDF end-to-end | âœ… Complete |
| **M3** | 6 | Can query and get answers | âœ… Complete |
| **M4** | 7 | Agent interface (MCP server) working | âœ… Complete |
| **M5** | 8 | KnowledgeGraph API + CLI complete | âœ… Complete |
| **M6** | 9 | Tests passing, docs complete | â³ Partial |

---

## Files to Create (Priority Order)

### Week 1-2 (Foundation)
1. `types/*.py` - Complete all type definitions âœ… DONE
2. `config/settings.py` - KGConfig implementation âœ… DONE
3. `providers/llm/openai.py` - OpenAI LLM provider âœ… DONE
4. `providers/embedding/openai.py` - OpenAI embeddings âœ… DONE

### Week 2-3 (Storage)
5. `storage/base.py` - Abstract interface âœ… DONE
6. `storage/parquet/backend.py` - Parquet operations âœ… DONE
7. `storage/lancedb/indices.py` - Vector indices âœ… DONE
8. `storage/duckdb/queries.py` - SQL queries âœ… DONE

### Week 3-5 (Ingestion)
9. `ingestion/chunking/markdown.py` - Markdown chunker âœ… DONE
10. `ingestion/chunking/pdf.py` - PDF converter âœ… DONE
11. `ingestion/extraction/extractor.py` - Chain-of-thought âœ… DONE
12. `ingestion/resolution/entity_dedup.py` - Deduplication âœ… DONE
13. `ingestion/resolution/entity_registry.py` - Cross-document matching âœ… DONE
14. `ingestion/resolution/topic_resolver.py` - Topic ontology resolution âœ… DONE
15. `ingestion/assembly/assembler.py` - Write to storage âœ… DONE

### Week 5-6 (Query)
16. `query/pipeline.py` - V7 orchestrator âœ… DONE
17. `query/decomposer.py` - Question decomposition âœ… DONE
18. `query/researcher.py` - Retrieval âœ… DONE
19. `query/synthesizer.py` - Answer synthesis âœ… DONE
20. `query/context_builder.py` - Context assembly âœ… DONE
21. `query/types.py` - Pipeline types âœ… DONE

### Week 6-7 (Agent Interface - MCP)
22. `mcp/__init__.py` - MCP module init âœ… DONE
23. `mcp/server.py` - MCP server with kg_execute tool âœ… DONE
24. `mcp/__main__.py` - Entry point âœ… DONE

### Week 7-8 (API)
23. `api/knowledge_graph.py` - Main class âœ… DONE
24. `cli/__init__.py` - CLI commands âœ… DONE
25. `cli/__main__.py` - Python -m entry point âœ… DONE

---

## Success Criteria

The package is complete when:

| Criterion | Description | Status |
|-----------|-------------|--------|
| **Zero infrastructure** | `pip install zomma-kg && python -c "from zomma_kg import KnowledgeGraph"` works | âœ… Ready |
| **End-to-end** | Can ingest a PDF and answer questions about it | âœ… Working |
| **Portable** | Knowledge base is a directory that can be zipped and shared | âœ… Working |
| **Agent-friendly** | MCP server with kg_execute tool for LLM agents | âœ… Working |
| **Tested** | Core functionality has test coverage | â³ Partial |
| **Documented** | README quickstart + Developer Guide; API docstrings partial | â³ Partial |
